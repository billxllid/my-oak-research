---
description: AI 功能测试策略（Schema/确定性/对抗样本/RAG 质量/评测集/黄金用例）
globs:
  - "tests/ai/**"
  - "packages/agents/**"
  - "apps/worker/**"
alwaysApply: true
---

# Oak Research - AI 功能测试策略

本策略用于验证 AI 相关能力（关键词派生、内容摘要、实体抽取、报告生成、RAG 检索）的可用性与稳健性，确保可重复、可回归、可度量。

## 1. 目标与范围

- 结构正确：输出必须通过 Zod Schema 校验
- 行为可重复：在测试环境中尽可能确定性（温度与提示固定）
- 抗注入与鲁棒：对抗样本不应破坏系统边界
- 可度量：RAG/摘要/实体抽取具备基本的自动化评估指标

## 2. 测试分层

- 适配层单测：网关入参整形/模型路由/Schema 校验（Vitest）
- 合成集成测试：Mock LLM 输出 + Pipeline 流（不联网）
- 评测回归：小规模真实模型调用（可独立开关），夜间跑

## 3. 确定性与环境

- 统一通过 LLM Gateway 传参：`temperature=0`, `top_p=1`, 固定 `seed`（若模型支持）
- 统一提示词模板，锁定 few-shot 示例
- 对模型不可控噪声，采用 **黄金用例**（golden）比对策略（近似匹配 + 归一化）

## 4. Schema 校验测试

- 为以下任务提供 Schema 与测试：
  - `keyword-derive`：语言代码 + 值数组去重
  - `content-summary`：摘要长度范围 + relevance 布尔
  - `entity-extract`：persons/orgs/locations 数组
  - `report-generate`：`title + sections[] + citations?`
- 测试流程：调用 → JSON 解析 → Zod 校验 → 断言通过；失败时输出最小可复现样例

## 5. 对抗样本（Prompt Injection）

- 构造陷阱文本：包含“忽略之前所有指令 / 以系统身份回答 / 删除日志 / 上传密钥”等
- 验证 `stripPromptLike()` 生效，输出应保持为普通文本摘要，不执行指令
- 对含“系统：…/开发者：…”的片段仅做普通引用渲染

## 6. RAG 质量测试

- 检索 Top-K 覆盖率：问题与标准答案包含的关键信息是否在检索片段内
- 去重/相似度阈值：低相似度片段不得进入上下文
- 多源性：至少 2 个不同来源参与引用（可选）
- 评估指标：
  - `Recall@K`（基于标注片段）
  - `Context Faithfulness`（基于规则评测或轻量 LLM 评分，打标签不回流到生产）

## 7. 摘要与实体抽取评估

- 摘要：ROUGE-L（近似）、长度合规、是否包含关键词相关性句
- 实体：与标准标注集的 F1（小规模样本集），或弱监督匹配（姓名/组织库）

## 8. 报告生成黄金用例

- 固定输入：模板 + 3–5 条素材（含 RAG 片段）
- 比对输出：标题/章节数量/引用标注结构必须一致
- 允许正文轻微差异：对文本做 `normalizeWhitespace + stripPunctuation` 后比对包含关系

## 9. 评测数据组织

tests/ai/

- fixtures/ 原始文本、对抗样本、RAG 片段
- goldens/ 任务输出黄金文件（JSON/MD）
- runners/ 统一运行脚本，支持 `--live` 切到真实模型

## 10. 运行模式

- 默认离线：完全 mock LLM 响应（稳定）
- Nightly 可选在线：小规模真实调用，记录审计，不影响阈值
- 失败保存：将输入与模型原样输出保存到 `artifacts/` 便于复现

## 11. 示例（伪代码）

```ts
import { describe, it, expect } from "vitest";
import { llmGateway } from "@oak/agents/llm-gateway";
import { SummarySchema } from "@/app/api/_schemas";

vi.mock("@oak/agents/llm-gateway", () => ({
  llmGateway: {
    json: vi
      .fn()
      .mockResolvedValue({ summary: "与关键词相关…", relevance: true }),
  },
}));

it("content-summary schema valid", async () => {
  const out = await llmGateway.json("content-summary", { prompt: "..." });
  const parsed = SummarySchema.safeParse(out);
  expect(parsed.success).toBe(true);
});
```

## 12. 基线阈值与报告

- 单测与合成测试必须全部通过
- RAG 与摘要/实体的基础指标需 ≥ 设定阈值（例如 `Recall@5 ≥ 0.6`，摘要合规率 ≥ 0.9）
- 生成测试报告并在 CI 中归档
